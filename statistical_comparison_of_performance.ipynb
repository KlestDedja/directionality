{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What we want to achieve in this notebook:\n",
    "- Pairwise Wilcoxon signed-rank + Holm correction (SciPy) + Critical Difference plot\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root_folder = os.getcwd()\n",
    "\n",
    "DATA_PATH = \"performance_comparison_gauss_1_clean.csv\"      # path to your CSV\n",
    "CSV_SEPARATOR = \",\"           # usually \",\" or \";\"\n",
    "DROP_AVERAGE_ROW = True       # drop last row if it is an average\n",
    "LOWER_IS_BETTER = True       # True for errors (RMSE, MAE), False for scores\n",
    "ALPHA = 0.05                  # significance level for our tests\n",
    "\n",
    "df_path = os.path.join(root_folder, \"data\", \"synthetic-golden-standard\", \"output-analysis\")\n",
    "data = pd.read_csv(os.path.join(df_path, DATA_PATH), sep=CSV_SEPARATOR)\n",
    "print(data.head(2))\n",
    "df = data[[\"HOG\", \"SCHARR\", \"SOBEL\", \"FIJI\"]]\n",
    "df\n",
    "\n",
    "print(df.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Friedman test + Nemenyi (post-hoc) test\n",
    "After Friedman test rejects the hypothesis that all methods are equivalent, we can run the Nemenyi (post-hoc) test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# Perform Friedman test\n",
    "# H0: All methods are on average the same\n",
    "# We pass each column as a separate argument to friedmanchisquare\n",
    "test_statistic, p_value = friedmanchisquare(*[df[col].values for col in df.columns])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FRIEDMAN TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"H0: All methods are sampled from the same population\")\n",
    "print(f\"Test statistic: {test_statistic:.6f}\")\n",
    "print(f\"P-value: {p_value:.6e}\")\n",
    "print(f\"Significance level (α): {ALPHA}\")\n",
    "print()\n",
    "if p_value < ALPHA:\n",
    "    print(f\"Result: REJECT H0 (p < {ALPHA})\")\n",
    "    print(\"Conclusion: There are significant differences between methods.\")\n",
    "else:\n",
    "    print(f\"Result: FAIL TO REJECT H0 (p ≥ {ALPHA})\")\n",
    "    print(\"Conclusion: No significant differences found between methods.\")\n",
    "print(\"=\" * 60)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Well, the rejection is pretty strong, so we can confidently move on with the post-hoc analaysis\n",
    "\n",
    "### Nemenyi test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata, studentized_range\n",
    "\n",
    "def mean_ranks(df: pd.DataFrame, higher_is_better: bool) -> pd.Series:\n",
    "    \"\"\"Mean ranks across rows; rank 1 = best.\"\"\"\n",
    "    x = df.to_numpy(dtype=float)\n",
    "    ranks = np.zeros_like(x)\n",
    "    for i in range(x.shape[0]):\n",
    "        ranks[i] = rankdata(-x[i] if higher_is_better else x[i], method=\"average\")\n",
    "    return pd.Series(ranks.mean(axis=0), index=df.columns, name=\"mean_rank\")\n",
    "\n",
    "\n",
    "def nemenyi_cd(n_datasets: int, n_methods: int, alpha: float = 0.05) -> float:\n",
    "    \"\"\"\n",
    "    Nemenyi critical difference for average ranks (Demšar 2006).\n",
    "    CD = q_alpha * sqrt(k(k+1)/(6N))\n",
    "    where q_alpha comes from the Studentized range distribution.\n",
    "    \"\"\"\n",
    "    if n_datasets <= 1:\n",
    "        raise ValueError(\"Need at least 2 datasets/rows to compute CD.\")\n",
    "    if n_methods <= 1:\n",
    "        raise ValueError(\"Need at least 2 methods/columns to compute CD.\")\n",
    "\n",
    "    # Studentized range critical value q_alpha for k groups, infinite dof\n",
    "    q_alpha = studentized_range.ppf(1 - alpha, n_methods, np.inf)\n",
    "    se = np.sqrt(n_methods * (n_methods + 1) / (6.0 * n_datasets))\n",
    "    return float(q_alpha * se)\n",
    "\n",
    "\n",
    "def nemenyi_pvals(mean_rank: pd.Series, n_datasets: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pairwise p-values for Nemenyi test based on average ranks.\n",
    "    p = 1 - CDF_studentized_range(q), where\n",
    "    q = |ri - rj| / sqrt(k(k+1)/(6N))\n",
    "    \"\"\"\n",
    "    methods = list(mean_rank.index)\n",
    "    k = len(methods)\n",
    "    se = np.sqrt(k * (k + 1) / (6.0 * n_datasets))\n",
    "\n",
    "    pmat = np.ones((k, k), dtype=float)\n",
    "    for i in range(k):\n",
    "        for j in range(i + 1, k):\n",
    "            q = abs(mean_rank.iloc[i] - mean_rank.iloc[j]) / se\n",
    "            p = 1.0 - studentized_range.cdf(q, k, np.inf)\n",
    "            pmat[i, j] = p\n",
    "            pmat[j, i] = p\n",
    "\n",
    "    return pd.DataFrame(pmat, index=methods, columns=methods)\n",
    "\n",
    "\n",
    "def _contiguous_nonsig_segments(\n",
    "    mean_rank_sorted: pd.Series, cd: float\n",
    ") -> list[tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Find contiguous segments (in sorted-by-rank order) where *all* pairs\n",
    "    within the segment have rank differences <= CD (i.e., not significant\n",
    "    under Nemenyi at alpha).\n",
    "\n",
    "    Returns list of (start_idx, end_idx) inclusive indices in the sorted list.\n",
    "    \"\"\"\n",
    "    r = mean_rank_sorted.to_numpy()\n",
    "    k = len(r)\n",
    "    segments: list[tuple[int, int]] = []\n",
    "\n",
    "    # Brute-force maximal contiguous segments:\n",
    "    # segment [i, j] is valid if max(r[i..j]) - min(r[i..j]) <= CD,\n",
    "    # but since r is sorted increasing, that's r[j]-r[i] <= CD.\n",
    "    i = 0\n",
    "    while i < k:\n",
    "        j = i\n",
    "        while j + 1 < k and (r[j + 1] - r[i]) <= cd:\n",
    "            j += 1\n",
    "        # Only draw segments of length >= 2\n",
    "        if j > i:\n",
    "            segments.append((i, j))\n",
    "        i += 1\n",
    "\n",
    "    # Reduce overlaps a bit: keep only segments that are not strict subsegments\n",
    "    reduced: list[tuple[int, int]] = []\n",
    "    for a, b in segments:\n",
    "        is_sub = any((c <= a and b <= d) and ((c, d) != (a, b)) for c, d in segments)\n",
    "        if not is_sub:\n",
    "            reduced.append((a, b))\n",
    "\n",
    "    # Sort by length descending then by start\n",
    "    reduced.sort(key=lambda t: (-(t[1] - t[0]), t[0]))\n",
    "    return reduced\n",
    "\n",
    "\n",
    "def critical_difference_diagram(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    higher_is_better: bool = True,\n",
    "    alpha: float = 0.05,\n",
    "    title: str | None = None,\n",
    "    figsize: tuple[float, float] = (10, 3.2),\n",
    "    label_rotation: float = 30.0,\n",
    ") -> tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"\n",
    "    Create a Demšar-style Critical Difference (CD) diagram with Nemenyi post-hoc.\n",
    "    df: rows = datasets, cols = methods.\n",
    "    \"\"\"\n",
    "    if df.isna().any().any():\n",
    "        raise ValueError(\"df contains NaNs. Please impute/drop before plotting.\")\n",
    "\n",
    "    n_datasets = df.shape[0]\n",
    "    n_methods = df.shape[1]\n",
    "\n",
    "    mr = mean_ranks(df, higher_is_better=higher_is_better)\n",
    "    mr_sorted = mr.sort_values()  # rank 1 best, so smaller is better\n",
    "    cd = nemenyi_cd(n_datasets=n_datasets, n_methods=n_methods, alpha=alpha)\n",
    "\n",
    "    # Prepare plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # Axis range (ranks are between 1..k)\n",
    "    k = n_methods\n",
    "    xmin, xmax = 1.0, float(k)\n",
    "    pad = 0.6\n",
    "    ax.set_xlim(xmin - pad, xmax + pad)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    # Baseline y levels\n",
    "    y_axis = 0.35\n",
    "    y_labels = 0.18\n",
    "    y_groups_top = 0.62\n",
    "\n",
    "    # Draw rank axis\n",
    "    ax.hlines(y_axis, xmin, xmax, linewidth=1.2)\n",
    "    for r in range(1, k + 1):\n",
    "        ax.vlines(r, y_axis - 0.02, y_axis + 0.02, linewidth=1.0)\n",
    "        ax.text(r, y_axis - 0.07, str(r), ha=\"center\", va=\"top\", fontsize=12)\n",
    "\n",
    "\n",
    "    # if ranks are too close, spread them a bit for better visibility. Push them right\n",
    "    # the later rank further down ( and so on, domino effect if needed)\n",
    "    plot_ranks = list(mr_sorted)\n",
    "\n",
    "    prev_rank = 0.5 # min rank is 1, so this never triggers in the beginning\n",
    "    for i, r in enumerate(plot_ranks):\n",
    "        if r - prev_rank < 0.25:\n",
    "            r += 0.25 - (r - prev_rank)\n",
    "            plot_ranks[i] = r\n",
    "        prev_rank = r\n",
    "    print(plot_ranks)\n",
    "    # Method markers + labels\n",
    "    i = 0\n",
    "    for name, rank in mr_sorted.items():\n",
    "        ax.plot([plot_ranks[i]], [y_axis], marker=\"o\", markersize=12)\n",
    "        ax.text(\n",
    "            plot_ranks[i],\n",
    "            y_labels,\n",
    "            name,\n",
    "            ha=\"right\",\n",
    "            va=\"center\",\n",
    "            rotation=label_rotation,\n",
    "            fontsize=14,\n",
    "        )\n",
    "        i += 1\n",
    "\n",
    "    # CD bar (like Orange)\n",
    "    cd_x0 = xmin\n",
    "    cd_x1 = min(xmax, xmin + cd)\n",
    "    ax.hlines(0.84, cd_x0, cd_x1, linewidth=2.0)\n",
    "    ax.vlines(cd_x0, 0.82, 0.86, linewidth=2.0)\n",
    "    ax.vlines(cd_x1, 0.82, 0.86, linewidth=2.0)\n",
    "    ax.text((cd_x0 + cd_x1) / 2, 0.88, f\"CD = {cd:.3f}\", ha=\"center\", va=\"bottom\", fontsize=14)\n",
    "    # if needed, we can add α={alpha} level as well\n",
    "    # Non-significant groups as thick bars above axis\n",
    "    segments = _contiguous_nonsig_segments(mr_sorted, cd=cd)\n",
    "    # stack bars to avoid overlap\n",
    "    level_step = 0.06\n",
    "    used_levels: list[list[tuple[float, float]]] = []\n",
    "\n",
    "    def place_segment(x0: float, x1: float) -> float:\n",
    "        for level_idx, intervals in enumerate(used_levels):\n",
    "            if all(x1 < a or x0 > b for a, b in intervals):\n",
    "                intervals.append((x0, x1))\n",
    "                return y_groups_top + level_idx * level_step\n",
    "        used_levels.append([(x0, x1)])\n",
    "        return y_groups_top + (len(used_levels) - 1) * level_step\n",
    "\n",
    "    for i, j in segments:\n",
    "        ranks = mr_sorted.to_numpy()\n",
    "        x0, x1 = float(ranks[i]), float(ranks[j])\n",
    "        y = place_segment(x0, x1)\n",
    "        ax.hlines(y, x0, x1, linewidth=4.0)\n",
    "\n",
    "    if title is None:\n",
    "        title = \"Critical Difference Diagram (Nemenyi)\"\n",
    "    ax.text((xmin + xmax) / 2, 1.1, title, ha=\"center\", va=\"top\", fontsize=16)\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Visualize results with critical difference plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = critical_difference_diagram(df, higher_is_better=not LOWER_IS_BETTER, alpha=ALPHA)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise p-values for Nemenyi test\n",
    "n_datasets = df.shape[0]\n",
    "mr = mean_ranks(df, higher_is_better=not LOWER_IS_BETTER)\n",
    "pmat_nemenyi = nemenyi_pvals(mr, n_datasets)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NEMENYI POST-HOC TEST - PAIRWISE P-VALUES\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Significance level (α): {ALPHA}\")\n",
    "print(f\"Critical difference (CD): {nemenyi_cd(n_datasets, df.shape[1], ALPHA):.3f}\")\n",
    "print()\n",
    "print(\"P-values for all pairwise comparisons:\")\n",
    "print(\"(P > 0.05: methods are connected in the CD diagram)\")\n",
    "print(\"(P ≤ 0.05: methods are NOT connected in the CD diagram)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "methods = list(pmat_nemenyi.index)\n",
    "for i in range(len(methods)):\n",
    "    for j in range(i + 1, len(methods)):\n",
    "        p_val = pmat_nemenyi.iloc[i, j]\n",
    "        print(f\"{methods[i]:25s} vs {methods[j]:25s} : p = {p_val:8f}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Full pairwise p-value matrix:\")\n",
    "print(pmat_nemenyi.round(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Wilcoxon Signed-Rank Test with Holm Correction\n",
    "\n",
    "Pairwise Wilcoxon signed-rank test for all method comparisons with Holm-Bonferroni correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "from itertools import combinations\n",
    "\n",
    "def wilcoxon_pairwise_with_holm(df: pd.DataFrame, alpha: float = 0.05) -> tuple[pd.DataFrame, list, list]:\n",
    "    \"\"\"\n",
    "    Perform pairwise Wilcoxon signed-rank tests with Holm-Bonferroni correction.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Rows = datasets/samples, Columns = methods/algorithms\n",
    "    alpha : float\n",
    "        Significance level\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pmat : pd.DataFrame\n",
    "        Matrix of p-values (uncorrected)\n",
    "    summary : list\n",
    "        List of dictionaries with results\n",
    "    results : list\n",
    "        Detailed results with corrections\n",
    "    \"\"\"\n",
    "    methods = df.columns.tolist()\n",
    "    k = len(methods)\n",
    "\n",
    "    # Generate all pairwise comparisons\n",
    "    pairs = list(combinations(range(k), 2))\n",
    "    n_comparisons = len(pairs)\n",
    "\n",
    "    # Collect results\n",
    "    results = []\n",
    "    p_values = []\n",
    "\n",
    "    for i, j in pairs:\n",
    "        method_i = methods[i]\n",
    "        method_j = methods[j]\n",
    "\n",
    "        # Wilcoxon signed-rank test: H0 that paired samples have same distribution\n",
    "        stat, p_val = wilcoxon(df.iloc[:, i].values, df.iloc[:, j].values, alternative='two-sided')\n",
    "        p_values.append(p_val)\n",
    "        results.append({\n",
    "            'method1': method_i,\n",
    "            'method2': method_j,\n",
    "            'statistic': stat,\n",
    "            'p_value': p_val,\n",
    "            'pair_idx': (i, j)\n",
    "        })\n",
    "\n",
    "    # Holm-Bonferroni correction\n",
    "    # Sort p-values in ascending order while keeping track of original indices\n",
    "    sorted_indices = np.argsort(p_values)\n",
    "    sorted_p_values = np.array(p_values)[sorted_indices]\n",
    "\n",
    "    # Apply Holm correction: multiply each p-value by (n_comparisons - rank + 1)\n",
    "    for rank, p_idx in enumerate(sorted_indices):\n",
    "        corrected_p = min(1.0, sorted_p_values[rank] * (n_comparisons - rank))\n",
    "        results[p_idx]['p_value_corrected'] = corrected_p\n",
    "        results[p_idx]['rejected'] = corrected_p < alpha\n",
    "\n",
    "    # Create p-value matrix\n",
    "    pmat = np.ones((k, k), dtype=float)\n",
    "    for i, j in pairs:\n",
    "        p_val = results[pairs.index((i, j))]['p_value']\n",
    "        pmat[i, j] = p_val\n",
    "        pmat[j, i] = p_val\n",
    "\n",
    "    pmat_df = pd.DataFrame(pmat, index=methods, columns=methods)\n",
    "\n",
    "    # Create summary with corrections\n",
    "    summary = []\n",
    "    for res in results:\n",
    "        summary.append({\n",
    "            'Method 1': res['method1'],\n",
    "            'Method 2': res['method2'],\n",
    "            'p-value': f\"{res['p_value']:.6f}\",\n",
    "            'p-value (Holm)': f\"{res['p_value_corrected']:.6f}\",\n",
    "            'Significant': res['rejected']\n",
    "        })\n",
    "\n",
    "    return pmat_df, summary, results\n",
    "\n",
    "\n",
    "# Run Wilcoxon test\n",
    "pmat_wilcoxon, summary_wilcoxon, results_wilcoxon = wilcoxon_pairwise_with_holm(df, alpha=ALPHA)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"WILCOXON SIGNED-RANK TEST (Pairwise) WITH HOLM-BONFERRONI CORRECTION\")\n",
    "print(\"=\" * 80)\n",
    "print(pd.DataFrame(summary_wilcoxon))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Interpretation: Significant=True means the two methods differ significantly\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wilcoxon_cd_diagram(\n",
    "    df: pd.DataFrame,\n",
    "    alpha: float = 0.05,\n",
    "    title: str | None = None,\n",
    "    figsize: tuple[float, float] = (10, 3.2),\n",
    "    label_rotation: float = 30.0,\n",
    ") -> tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"\n",
    "    Create a Critical Difference diagram for Wilcoxon signed-rank test results.\n",
    "    Methods are ordered by median performance, with non-significant groups connected.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Rows = datasets/samples, Columns = methods/algorithms\n",
    "    alpha : float\n",
    "        Significance level for Holm-corrected Wilcoxon test\n",
    "    title : str, optional\n",
    "        Plot title\n",
    "    figsize : tuple, optional\n",
    "        Figure size\n",
    "    label_rotation : float, optional\n",
    "        Rotation angle for method labels\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    fig, ax : matplotlib figure and axes\n",
    "    \"\"\"\n",
    "    if df.isna().any().any():\n",
    "        raise ValueError(\"df contains NaNs. Please impute/drop before plotting.\")\n",
    "\n",
    "    # Calculate median performance for each method (for ranking/ordering)\n",
    "    medians = df.median()\n",
    "    median_sorted = medians.sort_values()\n",
    "\n",
    "    # Run Wilcoxon test\n",
    "    pmat_df, summary, results = wilcoxon_pairwise_with_holm(df, alpha=alpha)\n",
    "\n",
    "    # Identify non-significant pairs (methods that are not significantly different)\n",
    "    methods = df.columns.tolist()\n",
    "    k = len(methods)\n",
    "\n",
    "    # Build graph of non-significant connections\n",
    "    not_sig_pairs = []\n",
    "    for res in results:\n",
    "        if not res['rejected']:  # p_value_corrected >= alpha\n",
    "            i = methods.index(res['method1'])\n",
    "            j = methods.index(res['method2'])\n",
    "            not_sig_pairs.append((i, j))\n",
    "\n",
    "    # Find connected components (groups of non-significantly different methods)\n",
    "    # Using simple union-find approach\n",
    "    parent = list(range(k))\n",
    "\n",
    "    def find(x):\n",
    "        if parent[x] != x:\n",
    "            parent[x] = find(parent[x])\n",
    "        return parent[x]\n",
    "\n",
    "    def union(x, y):\n",
    "        px, py = find(x), find(y)\n",
    "        if px != py:\n",
    "            parent[px] = py\n",
    "\n",
    "    for i, j in not_sig_pairs:\n",
    "        union(i, j)\n",
    "\n",
    "    # Group methods by their connected component\n",
    "    groups = {}\n",
    "    for i in range(k):\n",
    "        root = find(i)\n",
    "        if root not in groups:\n",
    "            groups[root] = []\n",
    "        groups[root].append(methods[i])\n",
    "\n",
    "    # Prepare plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # Axis range\n",
    "    xmin, xmax = 1.0, float(k)\n",
    "    pad = 0.6\n",
    "    ax.set_xlim(xmin - pad, xmax + pad)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    # Baseline y levels\n",
    "    y_axis = 0.35\n",
    "    y_labels = 0.18\n",
    "    y_groups_top = 0.62\n",
    "\n",
    "    # Draw rank axis with method names ordered by median\n",
    "    ax.hlines(y_axis, xmin, xmax, linewidth=1.2)\n",
    "\n",
    "    for idx, (name, rank) in enumerate(median_sorted.items()):\n",
    "        x_pos = idx + 1\n",
    "        ax.vlines(x_pos, y_axis - 0.02, y_axis + 0.02, linewidth=1.0)\n",
    "        ax.text(x_pos, y_axis - 0.07, str(idx + 1), ha=\"center\", va=\"top\", fontsize=12)\n",
    "\n",
    "    # Method markers + labels\n",
    "    for idx, (name, rank) in enumerate(median_sorted.items()):\n",
    "        x_pos = idx + 1\n",
    "        ax.plot([x_pos], [y_axis], marker=\"o\", markersize=12, color='C0')\n",
    "        ax.text(\n",
    "            x_pos,\n",
    "            y_labels,\n",
    "            name,\n",
    "            ha=\"right\",\n",
    "            va=\"center\",\n",
    "            rotation=label_rotation,\n",
    "            fontsize=14,\n",
    "        )\n",
    "\n",
    "    # Draw non-significant groups as horizontal lines\n",
    "    # Map method names to x positions\n",
    "    name_to_xpos = {}\n",
    "    for idx, (name, _) in enumerate(median_sorted.items()):\n",
    "        name_to_xpos[name] = idx + 1\n",
    "\n",
    "    # Draw connecting lines for non-significant groups\n",
    "    level_step = 0.06\n",
    "    used_levels = []\n",
    "\n",
    "    def place_segment(x0: float, x1: float) -> float:\n",
    "        for level_idx, intervals in enumerate(used_levels):\n",
    "            if all(x1 < a - 0.05 or x0 > b + 0.05 for a, b in intervals):\n",
    "                intervals.append((x0, x1))\n",
    "                return y_groups_top + level_idx * level_step\n",
    "        used_levels.append([(x0, x1)])\n",
    "        return y_groups_top + (len(used_levels) - 1) * level_step\n",
    "\n",
    "    # For each group, draw a line connecting all members\n",
    "    for group_methods in groups.values():\n",
    "        if len(group_methods) > 1:\n",
    "            x_positions = [name_to_xpos[m] for m in group_methods]\n",
    "            x_min = min(x_positions)\n",
    "            x_max = max(x_positions)\n",
    "            y = place_segment(x_min, x_max)\n",
    "            ax.hlines(y, x_min, x_max, linewidth=4.0, color='C0')\n",
    "\n",
    "    if title is None:\n",
    "        title = f\"Critical Difference Diagram (Wilcoxon signed-rank, α={alpha}, Holm corrected)\"\n",
    "    ax.text((xmin + xmax) / 2, 1.1, title, ha=\"center\", va=\"top\", fontsize=16)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "print(\"Wilcoxon CD diagram function defined and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = wilcoxon_cd_diagram(df, alpha=ALPHA)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Everything is significant according to this test (hence, the lame plot)\n",
    "Plus, the average ranking is not relevant for this test, as differences within measurements are used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
